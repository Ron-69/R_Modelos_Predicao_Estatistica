# R_Modelos_Predicao_Estatistica
Notebooks R explorando e implementando algoritmos de Machine Learning para Regress√£o e Classifica√ß√£o, utilizando o ecossistema Tidyverse e pacotes como caret e e1071.

# üìö Resumo de Modelos Preditivos em Machine Learning

Este reposit√≥rio cont√©m Notebooks (em R ou Python) que demonstram a implementa√ß√£o e o uso de diversos algoritmos de Machine Learning para resolver problemas de **Regress√£o** (previs√£o de valores quantitativos) e **Classifica√ß√£o** (previs√£o de categorias).

## üìà Modelos para Problemas de Regress√£o (Predi√ß√£o de Valores Quantitativos)

O objetivo principal √© prever uma vari√°vel de sa√≠da **cont√≠nua** ou **quantitativa** (ex: pre√ßo, temperatura).

| Categoria | Modelo | Descri√ß√£o |
| :--- | :--- | :--- |
| **Base** | **Regress√£o Linear** | Modelo inicial que assume uma rela√ß√£o linear. |
| **Base** | **Regress√£o Polinomial** | Usa transforma√ß√µes para modelar rela√ß√µes n√£o lineares. |
| **Regulariza√ß√£o** | **Regress√£o Ridge (L2)** | Penaliza coeficientes para evitar *overfitting* (encolhe, n√£o zera). |
| **Regulariza√ß√£o** | **Regress√£o Lasso (L1)** | Penaliza coeficientes e pode zer√°-los, servindo como **sele√ß√£o de *features***. |
| **Regulariza√ß√£o** | **Elastic Net** | Combina√ß√£o das penalidades Ridge e Lasso. |
| **Ensemble** | **Random Forest (Regress√£o)** | Combina muitas √Årvores de Decis√£o para alta precis√£o e redu√ß√£o de vari√¢ncia. |
| **Ensemble** | **Gradient Boosting Machines (GBM)** | Constr√≥i √°rvores sequencialmente, corrigindo erros (e.g., XGBoost, LightGBM). |
| **Dist√¢ncia** | **Support Vector Regression (SVR)** | Encontra um hiperplano que minimiza o erro dentro de uma margem ($\epsilon$). |
| **Dist√¢ncia** | **K-Nearest Neighbors (KNN Regress√£o)** | Prev√™ o valor como a m√©dia dos $K$ vizinhos mais pr√≥ximos. |

---
## ‚öñÔ∏è An√°lise Comparativa dos Modelos de Regress√£o Base

A transi√ß√£o da Regress√£o Linear Simples para a M√∫ltipla ilustra como a inclus√£o de *features* adicionais (como Horsepower, `hp`) altera a interpreta√ß√£o e a precis√£o do modelo, especialmente devido √† **multicolinearidade** existente entre as vari√°veis.

### Comparativo de M√©tricas (MPG vs. Peso e HP)

| M√©trica | Simples (`mpg ~ wt`) | M√∫ltiplo (`mpg ~ wt + hp`) | Interpreta√ß√£o da Mudan√ßa |
| :--- | :--- | :--- | :--- |
| **R-quadrado Ajustado** | 0.7446 | **0.8148** | **Melhoria de Ajuste:** O modelo m√∫ltiplo explica cerca de **7% a mais** da vari√¢ncia em MPG. |
| **RSE (Erro Residual)** | 3.046 | **2.593** | **Aumento da Precis√£o:** O erro m√©dio de previs√£o caiu em $\approx 0.45$ unidades, tornando o modelo mais preciso. |
| **Coeficiente do Peso (`wt`)** | **-5.3445** | **-3.87783** | **Multicolinearidade:** O impacto negativo do Peso diminuiu. Isso ocorre porque o Horsepower (`hp`), que √© correlacionado com o Peso, agora "explica" parte da redu√ß√£o no MPG. |
| **P-valor do `hp`** | N/A | $0.00145$ | **Signific√¢ncia:** O Horsepower √© um preditor estatisticamente significativo de MPG, mesmo **ap√≥s** a influ√™ncia do Peso ter sido contabilizada. |

### Conclus√£o da Compara√ß√£o

O modelo de Regress√£o M√∫ltipla √© **estatisticamente superior** ao modelo simples. Ele n√£o s√≥ fornece um ajuste superior (maior R-quadrado Ajustado e menor Erro Residual), mas tamb√©m oferece uma **interpreta√ß√£o mais precisa** do efeito isolado de cada *feature* no consumo de combust√≠vel (o princ√≠pio *ceteris paribus*).

## üìê An√°lise de Forma Funcional: Linear vs. Polinomial

Esta se√ß√£o compara o modelo Polinomial de 2¬∫ Grau (`mpg ~ hp + hp^2`) com o modelo de Regress√£o M√∫ltipla que foi o melhor ajuste linear (`mpg ~ wt + hp`), a fim de determinar a melhor forma de modelar a rela√ß√£o.

### Comparativo de Desempenho (R-quadrado Ajustado e Erro)

| M√©trica | Polinomial ($\text{hp} + \text{hp}^2$) | M√∫ltipla ($\text{wt} + \text{hp}$) | Compara√ß√£o/Conclus√£o |
| :--- | :--- | :--- | :--- |
| **R-quadrado Ajustado** | 0.7393 | **0.8148** | **Melhor Ajuste:** O modelo M√∫ltiplo explica significativamente mais vari√¢ncia. |
| **RSE (Erro Residual)** | 3.077 | **2.593** | **Maior Precis√£o:** O modelo M√∫ltiplo tem um erro de previs√£o consideravelmente menor. |
| **P-valor do $\text{I(hp}^2)$** | $\mathbf{0.000189}$ | N/A | **Validade da Curvatura:** A signific√¢ncia estat√≠stica confirma que a rela√ß√£o **n√£o √© linear**, embora a forma curvil√≠nea n√£o seja a que melhor prediz o alvo. |

### Conclus√£o sobre a Modelagem

1.  **A Rela√ß√£o √© N√£o-Linear:** O termo $\text{I(hp}^2)$ ser estatisticamente significativo prova que a rela√ß√£o entre $\text{HP}$ e $\text{MPG}$ tem uma **curvatura**.
2.  **O Melhor Modelo √© M√∫ltiplo:** Apesar de a forma ser curva, a inclus√£o de um segundo *feature* linear ($\text{wt}$) no modelo **M√∫ltiplo** resultou no **melhor ajuste geral** (maior $\text{R-quadrado Ajustado}$ e menor $\text{RSE}$).
3.  **Implica√ß√£o:** Para o *dataset* `mtcars`, a **combina√ß√£o de features independentes** ($\text{wt}$ e $\text{hp}$) √© mais eficaz para reduzir o erro de previs√£o do que a tentativa de modelar a curvatura de um √∫nico *feature* ($\text{hp}$).

---
## ‚öñÔ∏è Compara√ß√£o da Regulariza√ß√£o: Ridge (L2) vs. Lasso (L1)

Os modelos de regulariza√ß√£o s√£o cruciais para prevenir o *overfitting* em modelos lineares. Eles adicionam uma penalidade aos coeficientes ($\beta$) para mant√™-los est√°veis, utilizando a **Valida√ß√£o Cruzada (CV)** para encontrar o n√≠vel ideal dessa penalidade ($\lambda$).

| Caracter√≠stica | Regress√£o Ridge (Penalidade L2) | Regress√£o Lasso (Penalidade L1) |
| :--- | :--- | :--- |
| **Penalidade** | $\lambda \sum \beta_i^2$ (Soma dos Quadrados) | $\lambda \sum |\beta_i|$ (Soma dos Valores Absolutos) |
| **Efeito nos Coeficientes** | Encolhe os coeficientes em dire√ß√£o a zero, mas **nunca os zera**. | Pode for√ßar coeficientes irrelevantes a serem **exatamente zero** (Sele√ß√£o de Features). |

### üõ†Ô∏è An√°lise dos Coeficientes e Lambda Ideal ($\lambda_{\min}$)

A tabela compara os coeficientes no $\lambda$ que minimizou o erro para cada modelo.

| Feature | Coeficiente Ridge (L2) $\lambda=0.661$ | Coeficiente Lasso (L1) $\lambda=0.005$ | Observa√ß√£o |
| :--- | :--- | :--- | :--- |
| (Intercept) | $28.5312$ | $10.8383$ | O Lasso tende a penalizar o Intercepto mais agressivamente. |
| **nox** | $\mathbf{-12.8894}$ | $\mathbf{-9.0319}$ | O Ridge (L2) mant√©m um peso maior neste feature, distribuindo a penalidade de forma mais suave. |
| **rm** | $\mathbf{4.3723}$ | $\mathbf{6.3066}$ | O Lasso (L1) mant√©m um peso significativamente maior para este feature, concentrando o poder preditivo no `rm` (n√∫mero de quartos). |
| **age** | $-0.0036$ | $-0.0265$ | Ambos os modelos reduziram a import√¢ncia de `age`. |
| **indus** | $-0.0412$ | $0.0202$ | Os sinais opostos indicam como a penalidade lida com a multicolinearidade de maneira distinta. |

**Valores √ìtimos de Penalidade ($\lambda_{\min}$):**
* **Ridge (L2):** $\mathbf{0.6614818}$
* **Lasso (L1):** $\mathbf{0.005975135}$

### Conclus√µes sobre a Regulariza√ß√£o

1.  **Comportamento do Ridge (L2):**
    * O $\lambda_{\min}$ encontrado demonstra que o modelo Ridge precisa de uma penalidade moderada (0.66) para estabilidade.
    * Como esperado, **nenhum coeficiente foi zerado**, apenas encolhido. O Ridge √© o preferido quando todos os *features* s√£o considerados importantes.

2.  **Comportamento do Lasso (L1):**
    * O $\lambda_{\min}$ √© muito baixo (0.005), o que significa que o erro do modelo √© minimizado com uma penalidade muito fraca, e por isso, **nenhum *feature* foi anulado**.
    * O Lasso √© prefer√≠vel quando se busca explicitamente a sele√ß√£o de *features* ou quando o erro de previs√£o √© menor (menor RMSE) em compara√ß√£o com o Ridge.

## üï∏Ô∏è An√°lise Final: Elastic Net (Otimiza√ß√£o de Alpha e Lambda)

O Elastic Net combina as penalidades Ridge ($L_2$) e Lasso ($L_1$), otimizando dois hiperpar√¢metros: $\lambda$ (for√ßa da penalidade) e $\alpha$ (mistura entre $L_1$ e $L_2$).

### üõ†Ô∏è Par√¢metros Otimizados pelo `caret`

| Hiperpar√¢metro | Valor √ìtimo | Fun√ß√£o | Interpreta√ß√£o |
| :--- | :--- | :--- | :--- |
| **Melhor $\alpha$** | $\mathbf{0.1111}$ | $\alpha \in [0, 1]$. Onde 0 √© Ridge puro, e 1 √© Lasso puro. | **Predomin√¢ncia Ridge:** O $\alpha$ √≥timo √© muito pr√≥ximo de zero. Isso significa que o modelo que obteve o melhor desempenho utiliza uma penalidade **majoritariamente Ridge (L2)**, com apenas uma leve contribui√ß√£o do Lasso (L1). |
| **Melhor $\lambda$** | $\mathbf{0.2154}$ | For√ßa total da penalidade aplicada. | O modelo encontrou o ponto de equil√≠brio de regulariza√ß√£o que minimiza o erro. |

### üéØ Desempenho Final (RMSE)

| Modelo | Penalidade Aplicada | RMSE T√≠pico (Conjunto de Teste) |
| :--- | :--- | :--- |
| **Elastic Net (Optimal)** | $\mathbf{\alpha \approx 0.11}$ ($\text{L}_2$ dominante) | **5.179** |
| Lasso (L1 Puro) | $\alpha = 1$ | $\approx 6.357$ |
| Regress√£o M√∫ltipla (OLS) | $\lambda = 0$ | $\approx 5.5$ (sem regulariza√ß√£o) |

### Conclus√£o Global da Regress√£o

1.  **Modelo Ideal:** O **Elastic Net** foi o modelo de melhor desempenho (menor RMSE) entre os modelos lineares testados.
2.  **Estrat√©gia Vencedora:** O sucesso do Elastic Net reside na sua capacidade de escolher a melhor estrat√©gia de penaliza√ß√£o. O baixo valor de $\alpha$ indica que a melhor abordagem foi **priorizar a estabilidade** e o **encolhimento dos coeficientes (L2)** sobre a sele√ß√£o agressiva de *features* (L1).
3.  **Implica√ß√£o:** Para o *dataset* `Boston Housing`, a regulariza√ß√£o √© necess√°ria para reduzir o *overfitting* (melhora em rela√ß√£o ao OLS simples), e a forma ideal de faz√™-lo √© atrav√©s da **penalidade Ridge (L2)**.
---

## üè∑Ô∏è Modelos para Problemas de Classifica√ß√£o (Predi√ß√£o de Classes/Categorias)

O objetivo principal √© prever uma vari√°vel de sa√≠da **categ√≥rica** ou **discreta** (ex: Sim/N√£o, Classe A/B/C).

| Categoria | Modelo | Descri√ß√£o |
| :--- | :--- | :--- |
| **Probabil√≠stico** | **Regress√£o Log√≠stica** | Calcula a probabilidade de um dado pertencer a uma classe usando a fun√ß√£o Logit/Sigmoide. |
| **Probabil√≠stico** | **Naive Bayes** | Baseado no Teorema de Bayes; assume independ√™ncia ing√™nua dos *features*. |
| **Probabil√≠stico** | **Linear Discriminant Analysis (LDA)** | Encontra uma combina√ß√£o linear de *features* que melhor separa as classes. |
| **Margem** | **Support Vector Machines (SVM)** | Encontra o hiperplano que maximiza a margem entre as classes. |
| **Dist√¢ncia** | **K-Nearest Neighbors (KNN Classifica√ß√£o)** | Classifica um dado pela classe mais comum entre seus $K$ vizinhos pr√≥ximos. |
| **√Årvore** | **√Årvores de Decis√£o** | Cria regras de decis√£o sequenciais. |
| **Ensemble** | **Random Forest (Classifica√ß√£o)** | Vota√ß√£o de m√∫ltiplas √Årvores de Decis√£o para a classifica√ß√£o final. |
| **Ensemble** | **Gradient Boosting Machines (GBM)** | Constr√≥i preditores sequencialmente para alta precis√£o. |

### üéØ Regress√£o Log√≠stica 

Ao verificar o balanceamento do conjunto de dados, percebeu-se um desbalancemaneto entre Nao_Diabete e Diabete. Optou-se por aplicar estrat√©gia de balancemento para mitigar o problema

### ‚öñÔ∏è Estrat√©gia de Mitiga√ß√£o de Desbalanceamento (Custo)

O dataset `PimaIndiansDiabetes` apresentou um **desbalanceamento de 65% (Nao_Diabete) vs. 35% (Diabete)**. Para garantir que o modelo n√£o ignorasse a classe minorit√°ria cr√≠tica (`Diabete`), o treinamento da Regress√£o Log√≠stica foi realizado em duas etapas de compara√ß√£o:

1.  **Modelo Baseline:** Sem ajustes de peso.
2.  **Modelo Otimizado (Mitiga√ß√£o):** Treinado usando **pesos de classes inversamente proporcionais** √†s frequ√™ncias, penalizando os erros na classe `Diabete`.

#### An√°lise do Impacto da Mitiga√ß√£o (Valida√ß√£o Cruzada)

| M√©trica (M√©dia CV) | Baseline (Sem Ajuste) | Otimizado (Com Ajuste de Peso) | Conclus√£o Estrat√©gica |
| :--- | :--- | :--- | :--- |
| **ROC (AUC)** | $0.8392$ | $\mathbf{0.8396}$ | O poder discriminat√≥rio foi mantido. |
| **Sensibilidade (Recall) [Diabete]** | $\mathbf{0.8752}$ | $0.7857$ | **Diminui√ß√£o:** Indica que o Baseline estava com **Falsos Positivos excessivos** (Especificidade muito baixa). |
| **Especificidade [Nao\_Diabete]** | $0.5553$ | $\mathbf{0.7058}$ | **Melhoria Cr√≠tica:** A Especificidade aumentou em **15 pontos percentuais**, resultando em menos Falsos Positivos no teste. |

**Conclus√£o:** O **Modelo Otimizado** foi selecionado, pois alcan√ßou um **equil√≠brio** mais realista entre as classes e reduziu o alto vi√©s de Falso Positivo.

---

O modelo otimizado foi avaliado em um conjunto de dados de Teste (n√£o visto) para confirmar sua capacidade de generaliza√ß√£o.

### üíæ Persist√™ncia de Objetos (Reprodutibilidade)

Para garantir que o particionamento dos dados de treino e teste, as configura√ß√µes de Valida√ß√£o Cruzada (`control`) e os modelos treinados (como o `logreg_otimizado`) possam ser reutilizados em diferentes notebooks e sess√µes R, utilizamos as fun√ß√µes de serializa√ß√£o de dados:

* **`saveRDS(objeto, file = "caminho/nome.rds")`**: √â a fun√ß√£o preferida para salvar **um √∫nico objeto** (como um modelo ou a configura√ß√£o `control`). O arquivo `.rds` resultante √© carregado usando `readRDS()`, o que garante um controle expl√≠cito sobre qual objeto est√° sendo injetado na sess√£o.
* **`save(obj1, obj2, file = "caminho/nome.RData")`**: Usada para salvar **m√∫ltiplos objetos** simultaneamente (como `train_df` e `test_df`). O arquivo `.RData` √© carregado com a fun√ß√£o `load()`, que injeta todos os objetos salvos diretamente no ambiente de trabalho.

O uso dessas fun√ß√µes assegura que todas as an√°lises comparativas usem exatamente os mesmos *splits* de dados.

---

#### Matriz de Confus√£o

O resultado da Matriz de Confus√£o no Conjunto de Teste (70/30) √©:

#### M√©tricas de Desempenho

| M√©trica | Valor (Teste) | An√°lise / Interpreta√ß√£o |
| :--- | :--- | :--- |
| **AUC** | $\mathbf{0.8208}$ | **Forte Desempenho:** O modelo possui um bom poder de discrimina√ß√£o no conjunto n√£o visto. |
| **Acur√°cia** | $0.7261$ | A taxa de acerto geral √© de 72.61%. |
| **Sensibilidade (Recall)** | $0.7000$ | (Relativo √† classe 'Nao\_Diabete' - Padr√£o do caret). |
| **Especificidade** | $0.7750$ | (Relativo √† classe 'Diabete' - Padr√£o do caret). |
| **Recall (Diabete)** | $\mathbf{0.7750}$ | **Rec√°lculo Crucial:** O modelo identificou corretamente **77.50%** dos pacientes que realmente t√™m diabetes ($62 / (62 + 18)$). |
| **Balanced Accuracy** | $\mathbf{0.7375}$ | A acur√°cia ajustada para o desbalanceamento das classes. |

**Conclus√£o da Avalia√ß√£o:** O modelo final apresenta um bom equil√≠brio de desempenho ($\text{AUC} > 0.80$) e conseguiu identificar quase **$78\%$** dos casos reais de diabetes (Recall da classe minorit√°ria), sendo um excelente *baseline* para a compara√ß√£o com os pr√≥ximos modelos (KNN, SVM, etc.).

---

### üéØ Naive_Bayes

O Naive Bayes (NB) foi treinado com padroniza√ß√£o e otimizado usando Valida√ß√£o Cruzada (CV) repetida. O modelo escolhido foi o **`usekernel = TRUE`**, que apresentou o melhor desempenho de AUC.

| M√©trica | Valor √ìtimo (CV) |
| :--- | :--- |
| **ROC (AUC)** | $\mathbf{0.8301}$ |
| **Sensibilidade (Recall)** | $0.8467$ |
| **Especificidade** | $0.5794$ |

---

### üß† Linear Discriminant Analysis (LDA)

O modelo LDA (Linear Discriminant Analysis) n√£o possui hiperpar√¢metros de *tuning* e foi ajustado diretamente no *dataset* padronizado.

| M√©trica | Valor √ìtimo (CV) |
| :--- | :--- |
| **ROC (AUC)** | $0.8373$ |
| **Sensibilidade (Recall)** | $\mathbf{0.8800}$ |
| **Especificidade** | $0.5469$ |

## Compara√ß√£o da Categoria Probabil√≠stica

Foram comparados tr√™s modelos baseados em probabilidade para estabelecer o melhor *baseline* para modelos mais complexos.

#### Comparativo de M√©tricas (Valida√ß√£o Cruzada)

| M√©trica (M√©dia CV) | RegLog\_Opt | Naive\_Bayes | LDA | An√°lise |
| :--- | :--- | :--- | :--- | :--- |
| **ROC (AUC)** | $\mathbf{0.8396}$ | $0.8396$ | $0.8373$ | O poder de separa√ß√£o das classes √© similar entre os tr√™s. |
| **Sensibilidade (Recall)** | $0.7857$ | $0.7857$ | $\mathbf{0.8800}$ | O **LDA** demonstrou a melhor capacidade de minimiza√ß√£o de Falsos Negativos (Maior Recall). |
| **Especificidade** | $\mathbf{0.7058}$ | $0.7058$ | $0.5469$ | O **LDA** possui o maior vi√©s de Falso Positivo, tornando-o menos pr√°tico. |

**Conclus√£o da Categoria Probabil√≠stica:**
A **Regress√£o Log√≠stica Otimizada** √© escolhida como o modelo de *baseline* mais robusto. Embora o LDA tenha o maior Recall, o RegLog Otimizado oferece o **melhor equil√≠brio** entre as m√©tricas, mantendo um alto poder discriminat√≥rio (AUC) e uma Especificidade aceit√°vel ($\mathbf{0.7058}$).

### Support Vector Machines (SVM)

### üõ°Ô∏è Resultados do Modelo Support Vector Machines (SVM)

O modelo SVM com Kernel de Fun√ß√£o de Base Radial (RBF) foi treinado e otimizado para o par√¢metro de custo (**$C$**).

| M√©trica | Valor √ìtimo (CV) |
| :--- | :--- |
| **ROC (AUC)** | $0.8101$ |
| **Sensibilidade (Recall)** | $\mathbf{0.8647}$ |
| **Especificidade** | $0.5737$ |

**Conclus√£o:** O SVM **n√£o** alcan√ßou o maior Recall ($0.8647$), sendo superado pelo Recall do modelo LDA ($\mathbf{0.8800}$). Seu AUC ($0.8101$) √© ligeiramente inferior ao da Regress√£o Log√≠stica Otimizada ($0.8396$), e sua Especificidade ($0.5737$) √© baixa. Isso o posiciona como um modelo que, assim como o LDA, favorece muito a identifica√ß√£o da doen√ßa (alto Recall) √† custa de um alto n√∫mero de **Falsos Positivos** (baixa Especificidade), indicando um limite de decis√£o agressivo.

---

### üèòÔ∏è Resultados do Modelo K-Nearest Neighbors (KNN)

O modelo KNN (K-Vizinhos Mais Pr√≥ximos) foi treinado e otimizado para o par√¢metro **$k$** (o n√∫mero de vizinhos).

| M√©trica | Valor √ìtimo (CV) |
| :--- | :--- |
| **ROC (AUC)** | $0.8030$ |
| **Sensibilidade (Recall)** | $\mathbf{0.9381}$ |
| **Especificidade** | $0.4058$ |

**Conclus√£o:** O KNN obteve o **maior Recall** ($\mathbf{0.9381}$) de todos os modelos testados at√© agora, sendo o mais eficaz em identificar corretamente os casos positivos de diabetes. No entanto, o seu AUC ($\mathbf{0.8030}$) √© o mais baixo, e a **Especificidade √© extremamente baixa** ($0.4058$). Este modelo √© o menos equilibrado, favorecendo o Recall ao ponto de gerar uma taxa muito alta de **Falsos Positivos** (classificando pacientes saud√°veis como diab√©ticos), o que o torna impratic√°vel sem um ajuste rigoroso de *threshold*.

### Otimiza√ß√£o do KNN por aumento do Threshold(Limite)

### üèòÔ∏è Resultados do Modelo K-Nearest Neighbors (KNN) - Otimizado por Threshold

O modelo KNN ($k=33$) apresentava um Recall alt√≠ssimo (0.9381) mas uma Especificidade p√©ssima (0.4058). Foi aplicado um **ajuste de *Threshold*** (limite de decis√£o) para equilibrar o desempenho e maximizar a Sensibilidade e a Especificidade.

#### Matriz de Confus√£o (Threshold Otimizado - Conjunto de Teste)

#### M√©tricas de Desempenho

| M√©trica | Valor (Teste) | An√°lise / Conclus√£o |
| :--- | :--- | :--- |
| **Acur√°cia** | $0.7565$ | Melhora not√°vel sobre os modelos probabil√≠sticos. |
| **Recall (Diabete)** | $\mathbf{0.8375}$ | O Recall permanece alto ($83.75\%$), com uma queda controlada. |
| **Especificidade** | $\mathbf{0.7133}$ | A Especificidade melhorou dramaticamente, ficando no n√≠vel do RegLog Otimizado. |
| **Balanced Accuracy** | $\mathbf{0.7754}$ | **Melhor modelo at√© agora** em termos de equil√≠brio entre classes. |

**Conclus√£o Final do KNN:** O ajuste de *threshold* permitiu que o modelo KNN se tornasse o **modelo de melhor desempenho balanceado** at√© o momento, comprovando que seu alto poder discriminat√≥rio (Curva ROC) pode ser traduzido em m√©tricas de classifica√ß√£o √∫teis com a escolha correta do limite de decis√£o.

---